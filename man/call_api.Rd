% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/api.R
\name{call_api}
\alias{call_api}
\title{Call Language Model API}
\usage{
call_api(prompts, model, prompt_name, ...)
}
\arguments{
\item{prompts}{A list of prompts to send to the API. The class of this object
should match one of the supported APIs: "groq", "claude" (for the Anthropic
API), "openai", "gemini", or "llamafile" (for local
\href{https://github.com/mozilla-ocho/llamafile/}{llamafiles}).}

\item{model}{A string specifying the model to use.}

\item{prompt_name}{An optional string specifying the type of prompt.}

\item{...}{Additional arguments passed to specific \code{call_api} methods, such
as \code{max_retries}, \code{temperature}, \code{max_tokens}, \code{json_mode}, \code{system},
\code{pause_cap}, \code{llamafile_path}, or \code{log}.}
}
\value{
A tibble containing the API responses and usage information.
}
\description{
This generic function sends prompts to various language model APIs and
retrieves responses. It supports multiple APIs, including Groq, OpenAI,
Claude (Anthropic), and Gemini.
}
\details{
This function is implemented as a generic with methods for different
APIs:
\itemize{
\item call_api.groq
\item call_api.claude
\item call_api.openai
\item call_api.gemini
\item call_api.mistral
\item call_api.llamafile

Each method handles API-specific details such as endpoint URLs,
authentication, and response parsing.
}
}
\seealso{
\code{\link[=build_prompts_from_files]{build_prompts_from_files()}} for creating prompts to use with this
function.
}
