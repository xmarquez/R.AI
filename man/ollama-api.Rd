% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ollama-api.R
\name{completion.ollama_character}
\alias{completion.ollama_character}
\alias{list_models.ollama}
\alias{show_model_ollama}
\alias{pull_model_ollama}
\alias{push_model_ollama}
\alias{embed.ollama_character}
\alias{create.ollama}
\alias{delete.ollama}
\alias{copy.ollama}
\alias{list_running_models.ollama}
\title{Ollama API}
\usage{
\method{completion}{ollama_character}(
  prompt,
  model,
  suffix = NULL,
  images = NULL,
  options = NULL,
  system = NULL,
  template = NULL,
  stream = FALSE,
  raw = FALSE,
  keep_alive = "5m",
  ...
)

list_models.ollama(...)

show_model_ollama(model, verbose = FALSE, ...)

pull_model_ollama(model, insecure = FALSE, stream = FALSE, ...)

push_model_ollama(model, insecure = FALSE, stream = FALSE, ...)

\method{embed}{ollama_character}(content, model, truncate = TRUE, options = NULL, keep_alive = "5m", ...)

create.ollama(
  model,
  modelfile = NULL,
  path = NULL,
  quantize = NULL,
  stream = TRUE,
  ...
)

delete.ollama(model, ...)

copy.ollama(source, destination, ...)

list_running_models.ollama(...)
}
\arguments{
\item{prompt}{The input prompt (required for completion endpoints).}

\item{model}{The model to use (required for applicable endpoints).}

\item{suffix}{Text to append after the model response.}

\item{images}{A list of base64-encoded images for multimodal models.}

\item{system}{A system message to customize the behavior of the model.}

\item{template}{A prompt template to use.}

\item{stream}{Logical; whether to stream responses (default: FALSE).}

\item{raw}{Logical; whether to disable formatting (default: FALSE).}

\item{keep_alive}{Duration to keep the model in memory after the request.}

\item{...}{Additional arguments passed to the HTTP request.}

\item{verbose}{Logical; whether to return verbose information (default:
FALSE).}

\item{insecure}{Logical; whether to allow insecure connections (for pull/push
endpoints).}

\item{truncate}{Logical; whether to truncate inputs that exceed the model's
context length.}

\item{modelfile}{The content of the Modelfile for model creation.}

\item{path}{The path to the Modelfile for model creation.}

\item{quantize}{Quantization type for model creation.}

\item{source}{The source model for copying.}

\item{destination}{The destination model for copying.}

\item{messages}{A list of messages for chat completion (required for chat
endpoints).}

\item{tools}{Tools for the model to use in chat completions.}

\item{input}{The input text or list of texts for embeddings.}
}
\value{
A list with fields described in the API documentation.
}
\description{
Functions to interact with the Ollama server API.
}
\details{
For details about the API endpoints, visit
https://github.com/ollama/ollama/blob/main/docs/api.md.
}
