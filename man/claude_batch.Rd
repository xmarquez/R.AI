% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/claude-batch.R
\name{claude_batch}
\alias{claude_batch}
\title{Create and Poll a Claude Batch}
\usage{
claude_batch(
  prompts,
  model,
  timeout = 3600,
  max_tokens = 300,
  tidy = TRUE,
  quiet = FALSE
)
}
\arguments{
\item{prompts}{A list of prompts created by \code{\link[=build_prompts_from_files]{build_prompts_from_files()}}.}

\item{model}{The model to use for processing the batch. Defaults to the
result of \code{get_default_model("claude")}.}

\item{timeout}{A numeric value representing the time (in seconds) to wait
between polling attempts. Defaults to 3600 seconds (1 hour).}

\item{max_tokens}{The maximum number of output tokens for each item in the
batch. Defaults to 300.}

\item{tidy}{A logical value indicating whether to attempt to tidy the
resulting json into a tidy \link{tibble}. Default is \code{TRUE}; \code{FALSE} is useful
if you want to do the tidying separately or prefer the raw json.}

\item{quiet}{A logical value indicating whether the function should suppress
messages during retries and polling. Defaults to \code{FALSE}.}
}
\value{
A character vector containing each line of the .jsonl result file if
the batch completes successfully.
}
\description{
This function creates a message batch using the Anthropic API and then polls
the status until processing is complete. It simplifies the workflow of
creating and retrieving the results of a batch, especially for scenarios
where multiple message completions are required.
}
