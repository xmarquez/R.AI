% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/openai-batch.R
\name{openai_batch_job}
\alias{openai_batch_job}
\title{Submit OpenAI Batch Job}
\usage{
openai_batch_job(prompts, model, max_tokens = 300, quiet = FALSE)
}
\arguments{
\item{prompts}{A list of prompts, each containing messages to send to the
model, typically generated by \code{\link[=build_prompts_from_files]{build_prompts_from_files()}}. The prompts
should be structured in a format suitable for OpenAI's API.}

\item{model}{The model to use for processing the prompts (e.g.,
"gpt-3.5-turbo"). If not provided, the function will use the default model
set for OpenAI in your environment.}

\item{max_tokens}{An integer specifying the maximum number of tokens to
generate for each response. Defaults to 300.}

\item{quiet}{A logical value indicating whether to suppress messages during
the process. Defaults to FALSE.}
}
\value{
A list containing the batch job details, including the batch ID and
other metadata. The status of the job can be checked using
\code{\link[=openai_check_batch_status]{openai_check_batch_status()}}.
}
\description{
This function submits a batch job to OpenAI, which processes multiple prompts
concurrently using the specified model. It formats the prompts, uploads the
batch file, and creates the batch request.
}
