% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/token-methods.R
\name{tokens}
\alias{tokens}
\alias{tokenize}
\alias{detokenize}
\alias{token_count}
\alias{tokenize.llama_cpp_character}
\alias{detokenize.llama_cpp_tokenlist}
\alias{token_count.llama_cpp_character}
\alias{token_count.claude_list}
\alias{tokenize.cohere_character}
\alias{detokenize.cohere_tokenlist}
\alias{token_count.cohere_character}
\alias{token_count.gemini_list}
\title{Tokenize, Detokenize, and Count Tokens}
\usage{
tokenize(content, ...)

detokenize(tokens, ...)

token_count(content, ...)

\method{tokenize}{llama_cpp_character}(content, add_special = FALSE, with_pieces = FALSE, ...)

\method{detokenize}{llama_cpp_tokenlist}(tokens, ...)

\method{token_count}{llama_cpp_character}(content, ...)

\method{token_count}{claude_list}(content, model, quiet = FALSE, ...)

\method{tokenize}{cohere_character}(content, model = NULL, ...)

\method{detokenize}{cohere_tokenlist}(tokens, model = NULL, ...)

\method{token_count}{cohere_character}(content, model = NULL, ...)

\method{token_count}{gemini_list}(content, model = "gemini-1.5-flash", ...)
}
\arguments{
\item{content}{A character vector of text to tokenize or count, or a list of
messages created by \code{\link[=format_chat]{format_chat()}} to count tokens for (Claude only).}

\item{...}{Additional arguments passed to each method, potentially including
API keys, extra parameters, or other backend-specific settings.}

\item{tokens}{An integer or numeric vector of token IDs to detokenize.}

\item{add_special}{(llama.cpp only) Boolean controlling how the text is
split.}

\item{with_pieces}{(llama.cpp only) Boolean controlling whether to return
token pieces.}

\item{model}{For backends like Cohere or Claude, a string specifying which
model's tokenizer to use.}

\item{quiet}{Suppress retry messages.}
}
\value{
\itemize{
\item \strong{tokenize()}: Returns a vector (or list) of token IDs, often with a custom class like
\code{"llama_cpp_tokenlist"} or \code{"cohere_tokenlist"}.
\item \strong{detokenize()}: Returns a character string (or vector of strings) that reconstructs
the original text from the token IDs. The object often has a custom class
like \code{"llama_cpp_character"}.
\item \strong{token_count()}: Returns an \strong{integer} (or numeric) value indicating how many
tokens are used in the input text.
}
}
\description{
These functions provide three generics for token manipulation:
}
\details{
\enumerate{
\item \strong{\code{tokenize(content, ...)}} Splits text (a character vector) into
tokens (e.g. integer IDs).
\item \strong{\code{detokenize(tokens, ...)}} Converts integer token IDs back into
text.
\item \strong{\code{token_count(content, ...)}} Returns the number of tokens used by
a given model or backend, typically by calling \code{tokenize()} internally.
}
}
\examples{
\dontrun{
# Example: llama.cpp usage. Requires a running llama.cpp instance.
# 1) Tokenize
txt <- "Hello world!"
class(txt) <- c("llama_cpp_character", "character")
tokens <- tokenize(txt, add_special=FALSE)

# 2) Detokenize
class(tokens) <- c("llama_cpp_tokenlist", "integer")
detok <- detokenize(tokens)
cat(detok)

# 3) Count tokens
# For llama.cpp, we do the same as tokenize but just return length(tokens).

# Example: Cohere usage
txt_cohere <- "This is a test for Cohere tokenization."
class(txt_cohere) <- c("cohere_character", "character")

# Tokenize with optional model
co_tokens <- tokenize(txt_cohere, model = "command-r-plus-08-2024")

# Count tokens (calls tokenize internally)
n_toks <- token_count(txt_cohere, model = "command-r-plus-08-2024")
print(n_toks)

# Detokenize (reconstruct text)
class(co_tokens) <- c("cohere_tokenlist", "integer")
retext <- detokenize(co_tokens, model = "command-r-plus-08-2024")
cat(retext)
}

}
