#' Format Prompts for OpenAI Batch API
#'
#' This function transforms a list of prompts generated by
#' [build_prompts_from_files()] into the appropriate JSONL format required for
#' the OpenAI Batch API.
#'
#' @param prompts A list of prompts with each prompt containing a list of
#'   messages (role and content).
#' @param model The model to use for processing each prompt (e.g.,
#'   "gpt-3.5-turbo-0125").
#' @param max_tokens Max number of tokens for each response. Defaults to 300.
#'
#' @return A character string formatted in JSONL, ready to be saved to a file.
#' @export
openai_format_prompts_for_batch <- function(prompts, model, max_tokens = 300) {
  json_lines <- lapply(names(prompts), function(name) {
    list(
      custom_id = name,
      method = "POST",
      url = "/v1/chat/completions",
      body = list(
        model = model,
        messages = prompts[[name]],
        max_tokens = max_tokens
      )
    )
  })
  jsonl_string <- paste(sapply(json_lines, jsonlite::toJSON, auto_unbox = TRUE), collapse = "\n")
  jsonl_string
}

#' Upload JSONL File to OpenAI for Batch Processing
#'
#' This function uploads a JSONL file to OpenAI for batch processing using the
#' Files API.
#'
#' @param jsonl The JSONL string generated by
#'   [openai_format_prompts_for_batch()].
#' @param max_retries An integer indicating the maximum number of retry attempts
#'   in case of request failures. Defaults to 3.
#' @param pause_cap A numeric value representing the maximum pause duration (in
#'   seconds) between retries. Defaults to 1200.
#' @param quiet A logical value indicating whether the function should suppress
#'   messages during retries. Defaults to `FALSE`.
#'
#' @return A list containing the response details, including the file ID.
#' @export
openai_upload_batch_file <- function(jsonl, max_retries = 3, pause_cap = 1200, quiet = FALSE) {
  # Make the API call to upload the file using httr::RETRY to handle retries

  tmp_file <- fs::file_temp(ext = "jsonl")
  writeLines(jsonl, tmp_file)

  res <- httr::RETRY(
    verb = "POST",
    url = "https://api.openai.com/v1/files",
    config = httr::add_headers(
      "Authorization" = paste("Bearer", Sys.getenv("OPENAI_API_KEY")),
      "Content-Type" = "multipart/form-data"
    ),
    body = list(
      purpose = "batch",
      file = httr::upload_file(tmp_file)
    ),
    times = max_retries,
    pause_base = 1,
    pause_cap = pause_cap,
    quiet = quiet
  )

  # Check if the response contains an error
  httr::stop_for_status(res)
  response <- httr::content(res)

  # Return the response details
  response
}

#' Create OpenAI Batch Request
#'
#' This function creates a batch request using the uploaded file ID from the
#' OpenAI Batch API.
#'
#' @param upload_response The response object returned by
#'   [openai_upload_batch_file()] containing the uploaded file ID.
#' @param endpoint The endpoint for processing each request in the batch, e.g.,
#'   "/v1/chat/completions".
#' @param completion_window A string specifying the completion window, currently
#'   must be "24h".
#' @param max_retries An integer indicating the maximum number of retry attempts
#'   in case of request failures. Defaults to 3.
#' @param pause_cap A numeric value representing the maximum pause duration (in
#'   seconds) between retries. Defaults to 1200.
#' @param quiet A logical value indicating whether the function should suppress
#'   messages during retries. Defaults to `FALSE`.
#'
#' @return A list containing the response details, including batch ID and
#'   status.
#' @export
openai_create_batch <- function(upload_response, endpoint = "/v1/chat/completions",
                                completion_window = "24h", max_retries = 3,
                                pause_cap = 1200, quiet = FALSE) {

  stopifnot(completion_window == "24h")

  file_id <- upload_response$id

  body <- jsonlite::toJSON(
    list(
      input_file_id = file_id,
      endpoint = endpoint,
      completion_window = completion_window
    ),
    auto_unbox = TRUE,
    pretty = TRUE
  )

  res <- retry_response(base_url = "https://api.openai.com/v1/batches",
                        api_key = Sys.getenv("OPENAI_API_KEY"),
                        response_format = NULL,
                        body = body,
                        max_retries = max_retries,
                        pause_cap = pause_cap,
                        quiet = quiet)

  # Check if the response contains an error
  httr::stop_for_status(res)
  response <- httr::content(res)

  # Return the response details
  response
}

#' Check Status of OpenAI Batch Request
#'
#' This function checks the status of an existing batch request using the OpenAI
#' Batch API.
#'
#' @param batch_response The response object returned by [openai_create_batch()]
#'   containing the batch ID.
#' @param max_retries An integer indicating the maximum number of retry attempts
#'   in case of request failures. Defaults to 3.
#' @param pause_cap A numeric value representing the maximum pause duration (in
#'   seconds) between retries. Defaults to 1200.
#' @param quiet A logical value indicating whether the function should suppress
#'   messages during retries. Defaults to `FALSE`.
#'
#' @return A list containing the current status of the batch, including the
#'   status field.
#' @export
openai_check_batch_status <- function(batch_response, max_retries = 3, pause_cap = 1200, quiet = FALSE) {
  batch_id <- batch_response$id

  url <- paste0("https://api.openai.com/v1/batches/", batch_id)

  res <- httr::RETRY(
    verb = "GET",
    url = url,
    config = httr::add_headers(
      "Authorization" = paste("Bearer", Sys.getenv("OPENAI_API_KEY")),
      "Content-Type" = "application/json"
    ),
    times = max_retries,
    pause_base = 1,
    pause_cap = pause_cap,
    quiet = quiet
  )

  # Check if the response contains an error
  httr::stop_for_status(res)
  response <- httr::content(res)

  # Return the response details
  response
}

#' Download Results of OpenAI Batch Request
#'
#' This function downloads the results of a completed batch request using the
#' output file ID from the OpenAI Batch API.
#'
#' @param batch_status The status object returned by
#'   [openai_check_batch_status()] or [openai_create_batch()] containing the
#'   `output_file_id` field.
#' @param max_retries An integer indicating the maximum number of retry attempts
#'   in case of request failures. Defaults to 3.
#' @param pause_cap A numeric value representing the maximum pause duration (in
#'   seconds) between retries. Defaults to 1200.
#' @param quiet A logical value indicating whether the function should suppress
#'   messages during retries. Defaults to `FALSE`.
#' @param tidy A logical value indicating whether to attempt to tidy the
#'   resulting json into a tidy [tibble]. Default is `TRUE`; `FALSE` is useful
#'   if you want to do the tidying separately or prefer the raw json.
#'
#' @return A character vector containing each line of the .jsonl result file.
#' @export
openai_download_batch_results <- function(batch_status, max_retries = 3, pause_cap = 1200, quiet = FALSE, tidy = TRUE) {
  output_file_id <- batch_status$output_file_id

  if (is.null(output_file_id)) {
    stop("The batch is not yet complete or there is no output file available.")
  }

  url <- paste0("https://api.openai.com/v1/files/", output_file_id, "/content")

  res <- httr::RETRY(
    verb = "GET",
    url = url,
    config = httr::add_headers(
      "Authorization" = paste("Bearer", Sys.getenv("OPENAI_API_KEY"))
    ),
    times = max_retries,
    pause_base = 1,
    pause_cap = pause_cap,
    quiet = quiet
  )

  # Check if the response contains an error
  httr::stop_for_status(res)
  response_content <- httr::content(res, as = "text")

  if(tidy) {
    # Tidy response
    response_content <- jsonlite::stream_in(textConnection(response_content), verbose = !quiet) |>
      tibble::as_tibble() |>
      tidyr::unnest("response") |>
      dplyr::rename(openai_id = "id") |>
      tidyr::unnest("body") |>
      dplyr::rename(object_id = "id",
                    id = "custom_id") |>
      tidyr::unnest("choices") |>
      tidyr::unnest("message") |>
      dplyr::rename(response = "content") |>
      tidyr::unnest("usage")
  }

  response_content
}

#' Poll OpenAI Batch Status and Retrieve Results
#'
#' This function continuously polls the status of a batch until processing is
#' complete. If the status is "completed" or "expired", it downloads the
#' results. If the status is "in_progress", "validating", or "finalizing", it
#' waits for the specified timeout before polling again. If the status is
#' "cancelling", "cancelled", or "failed, it stops and provides an informative
#' message.
#'
#' @param batch_response A list returned by `openai_create_batch` or
#'   `openai_check_batch_status` containing batch details.
#' @param timeout A numeric value representing the time (in seconds) to wait
#'   between polling attempts. Defaults to 3600 seconds (1 hour).
#' @param max_retries An integer indicating the maximum number of retry attempts
#'   in case of request failures. Defaults to 3.
#' @param pause_cap A numeric value representing the maximum pause duration (in
#'   seconds) between retries. Defaults to 1200.
#' @param tidy A logical value indicating whether to attempt to tidy the
#'   resulting JSON into a tidy [tibble]. Default is `TRUE`; `FALSE` is useful
#'   if you want to do the tidying separately or prefer the raw JSON.
#' @param quiet A logical value indicating whether the function should suppress
#'   messages during retries. Defaults to `FALSE`.
#'
#' @return A character vector containing each line of the .jsonl result file if
#'   the batch completes successfully.
#' @export
openai_poll_and_retrieve_results <- function(batch_response, timeout = 3600,
                                             max_retries = 3, pause_cap = 1200,
                                             tidy = TRUE, quiet = FALSE) {
  repeat {
    # Retrieve the current status of the batch
    status_response <- openai_check_batch_status(batch_response, max_retries = max_retries,
                                                 pause_cap = pause_cap, quiet = quiet)

    processing_status <- status_response$status
    output_file_id <- status_response$output_file_id

    if (processing_status == "completed" && !is.null(output_file_id)) {
      message("Batch processing completed. Retrieving results...")
      results <- openai_download_batch_results(status_response, max_retries = max_retries,
                                               pause_cap = pause_cap, quiet = quiet, tidy = tidy)
      return(results)
    } else if (processing_status == "expired" && !is.null(output_file_id)) {
      message("Batch processing expired. Retrieving available results...")
      results <- openai_download_batch_results(status_response, max_retries = max_retries,
                                               pause_cap = pause_cap, quiet = quiet, tidy = tidy)
      return(results)
    } else if (processing_status == "in_progress" ||
               processing_status == "validating" ||
               processing_status == "finalizing") {
      if(processing_status == "finalizing") {
        timeout <- timeout/10
      }
      message(glue::glue("{lubridate::now()}: Batch still in progress. Waiting for {timeout} seconds before next poll..."))
      Sys.sleep(timeout)
    } else {
      stop("Batch ", processing_status, ".")
    }
  }
}

#' Cancel OpenAI Batch Request
#'
#' This function cancels an ongoing batch request using the OpenAI Batch API.
#'
#' @param batch_response The response object returned by [openai_create_batch()]
#'   or [openai_check_batch_status()] containing the batch ID.
#' @param max_retries An integer indicating the maximum number of retry attempts
#'   in case of request failures. Defaults to 3.
#' @param pause_cap A numeric value representing the maximum pause duration (in
#'   seconds) between retries. Defaults to 1200.
#' @param quiet A logical value indicating whether the function should suppress
#'   messages during retries. Defaults to `FALSE`.
#'
#' @return A list containing the response details after the cancel request is
#'   submitted.
#' @export
openai_cancel_batch <- function(batch_response, max_retries = 3, pause_cap = 1200, quiet = FALSE) {
  batch_id <- batch_response$id

  url <- paste0("https://api.openai.com/v1/batches/", batch_id, "/cancel")

  res <- httr::RETRY(
    verb = "POST",
    url = url,
    config = httr::add_headers(
      "Authorization" = paste("Bearer", Sys.getenv("OPENAI_API_KEY")),
      "Content-Type" = "application/json"
    ),
    times = max_retries,
    pause_base = 1,
    pause_cap = pause_cap,
    quiet = quiet
  )

  # Check if the response contains an error
  httr::stop_for_status(res)
  response <- httr::content(res)

  # Return the response details
  response
}

#' List OpenAI Batches
#'
#' This function lists all the batches being processed for a user using the
#' OpenAI Batch API.
#'
#' @param limit An integer specifying the maximum number of batches to return.
#'   Defaults to 10.
#' @param max_retries An integer indicating the maximum number of retry attempts
#'   in case of request failures. Defaults to 3.
#' @param pause_cap A numeric value representing the maximum pause duration (in
#'   seconds) between retries. Defaults to 1200.
#' @param quiet A logical value indicating whether the function should suppress
#'   messages during retries. Defaults to `FALSE`.
#'
#' @return A list containing the details of the batches.
#' @export
openai_list_batches <- function(limit = 10, max_retries = 3, pause_cap = 1200, quiet = FALSE) {
  url <- paste0("https://api.openai.com/v1/batches?limit=", limit)

  res <- httr::RETRY(
    verb = "GET",
    url = url,
    config = httr::add_headers(
      "Authorization" = paste("Bearer", Sys.getenv("OPENAI_API_KEY")),
      "Content-Type" = "application/json"
    ),
    times = max_retries,
    pause_base = 1,
    pause_cap = pause_cap,
    quiet = quiet
  )

  # Check if the response contains an error
  httr::stop_for_status(res)
  response <- httr::content(res)

  # Return the response details
  response
}

#' Execute OpenAI Batch Workflow
#'
#' This function orchestrates the entire OpenAI batch process: it formats the
#' prompts, uploads the batch file, creates the batch request, and polls until
#' the results are ready.
#'
#' @param prompts A list of prompts, each containing messages to send to the
#'   model, generated by [build_prompts_from_files()].
#' @param model The model to use for processing the prompts, e.g.,
#'   "gpt-3.5-turbo". If not specified, the function will use a default model.
#' @param timeout A numeric value representing the time (in seconds) to wait
#'   between polling attempts. Defaults to 3600 seconds (1 hour).
#' @param max_tokens The maximum number of tokens to generate for each response.
#'   Defaults to 300.
#' @param quiet A logical value indicating whether the function should suppress
#'   messages during the process. Defaults to `FALSE`.
#'
#' @return A tibble or a character vector containing each line of the .jsonl
#'   result file, depending on the value of `tidy` in
#'   `openai_poll_and_retrieve_results`.
#' @export
openai_batch <- function(prompts, model, timeout = 3600, max_tokens = 300, quiet = FALSE) {

  checkmate::assert_class(prompts, "openai")
  if(missing(model)) {
    model <- get_default_model("openai")
  }
  jsonl <- openai_format_prompts_for_batch(prompts, model = model)
  batch_file <- openai_upload_batch_file(jsonl = jsonl, quiet = quiet)
  batch <- openai_create_batch(batch_file, quiet = quiet)
  result <- openai_poll_and_retrieve_results(batch, timeout = timeout, quiet = quiet)
  result
}
