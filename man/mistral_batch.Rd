% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mistral-batch.R
\name{mistral_batch}
\alias{mistral_batch}
\title{Execute Mistral Batch Workflow}
\usage{
mistral_batch(prompts, model, timeout = 3600, max_tokens = 100, quiet = FALSE)
}
\arguments{
\item{prompts}{A list of prompts, each containing messages to send to the model.}

\item{model}{The model to use for processing the prompts, e.g., "mistral-small-latest". If not specified, the function will use a default model.}

\item{timeout}{A numeric value representing the time (in seconds) to wait between polling attempts. Defaults to 3600 seconds (1 hour).}

\item{max_tokens}{The maximum number of tokens to generate for each response. Defaults to 100.}

\item{quiet}{A logical value indicating whether the function should suppress messages during the process. Defaults to \code{FALSE}.}
}
\value{
A character vector containing each line of the .jsonl result file.
}
\description{
This function orchestrates the entire Mistral batch process: it formats the prompts, uploads the batch file, creates the batch job, and polls until the results are ready.
}
