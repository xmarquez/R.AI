% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ask.R
\name{ask}
\alias{ask}
\title{Ask a Language Model}
\usage{
ask(
  prompt,
  api,
  system,
  data,
  model,
  output = stdout(),
  response_only = TRUE,
  ...
)
}
\arguments{
\item{prompt}{The input prompt to send to the API. Can be a character vector
(including file names - see \code{\link[=prompt_list]{prompt_list()}}), a prompt produced by
\code{\link[=prompt]{prompt()}}, or an object of class \code{combined_prompts} produced by
\code{\link[=prompt_list]{prompt_list()}}.}

\item{api}{A string specifying the API to use. Must be one of \code{"gemini"},
\code{"claude"}, \code{"openai"}, \code{"llamafile"}, "\code{groq}", or \code{"mistral"}. Must be
specified if the prompt is a character vector.}

\item{system}{Optional. A character string providing system-level
instructions or context for the API.}

\item{data}{Optional. A data frame containing variables to be interpolated
into \code{prompt} using \code{\link[stringr:str_glue]{stringr::str_glue_data()}}.}

\item{model}{A character string specifying the model to use. Defaults to the
model returned by \code{\link[=get_default_model]{get_default_model()}} for the specified API.}

\item{output}{Where to write the response. Defaults to \code{stdout()}. If a
character string, writes the response to the specified file. Ignored if
\code{response_only} is \code{FALSE}.}

\item{response_only}{Logical. If \code{TRUE}, returns only the response content
from the API. If \code{FALSE}, returns the full response object, including usage
statistics. Defaults to \code{TRUE}.}

\item{...}{Additional arguments passed to the API call in \code{\link[=call_api]{call_api()}},
including, e.g., \code{temperature} or \code{max_tokens}. See the documentation in
\code{\link[=call_api]{call_api()}} for more.}
}
\value{
The model's response. By default, the function returns only the
response content as a character string. If \code{response_only = FALSE}, the
full response object is returned as a \code{\link[tibble:tibble]{tibble::tibble()}}, including usage
statistics. Defaults to \code{TRUE}.
}
\description{
The \code{ask} function provides a unified interface for sending a single prompt
to a language model API. It supports different input types and APIs, ensuring
integration with models from the Groq, Gemini, OpenAI, Anthropic, and Mistral
APIs, and local llamafiles.
}
\examples{
\dontrun{
# Ask a question using OpenAI API
response <- ask(
  prompt = "What is the capital of France?",
  api = "openai",
  system = "You are a helpful assistant."
)
print(response)

# Save the response to a file
ask(
  prompt = "Explain quantum computing in a brief poem.",
  api = "gemini",
  system = "You are a helpful tutor.",
  output = "response.txt",
)
}

}
\seealso{
\itemize{
\item \code{\link[=prompt_list]{prompt_list()}} for creating structured prompts from user input.
\item \code{\link[=call_api]{call_api()}} for sending API requests with structured prompts.
}
}
\concept{chat}
