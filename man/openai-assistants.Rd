% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/openai-assistants.R
\name{openai_create_assistant}
\alias{openai_create_assistant}
\alias{openai_list_assistants}
\alias{openai_get_assistant}
\alias{openai_update_assistant}
\alias{openai_delete_assistant}
\title{Create, list, retrieve or delete an OpenAI Assistant}
\usage{
openai_create_assistant(
  name = NULL,
  description = NULL,
  instructions = NULL,
  model,
  tools = NULL,
  tool_resources = NULL,
  metadata = NULL,
  temperature = 0.2,
  top_p = NULL,
  response_format = "auto"
)

openai_list_assistants(limit = 20, order = "desc", after = NULL, before = NULL)

openai_get_assistant(assistant_id)

openai_update_assistant(
  assistant_id,
  name = NULL,
  description = NULL,
  instructions = NULL,
  model = NULL,
  tools = NULL,
  tool_resources = NULL,
  metadata = NULL,
  temperature = NULL,
  top_p = NULL,
  response_format = NULL
)

openai_delete_assistant(assistant_id)
}
\arguments{
\item{name}{Character. Name of the assistant. The maximum length is 256
characters.}

\item{description}{Character. The description of the assistant. The maximum
length is 512 characters.}

\item{instructions}{Character. Instructions for the assistant. The maximum
length is 256,000 characters.}

\item{model}{Character. Model to use for the assistant (e.g., "gpt-4o"). Get
available models via \code{\link[=list_models]{list_models()}}.}

\item{tools}{List. Tools the assistant can use. A list of tools enabled on
the assistant. There can be a maximum of 128 tools per assistant. Tools can
be of types \code{code_interpreter}, \code{file_search}, or \code{function}. See
\url{https://platform.openai.com/docs/api-reference/assistants/createAssistant}
for details. Normally you would specify them as \code{list(type = "code_interpreter")}.}

\item{tool_resources}{A set of resources that are used by the assistant's
tools. The resources are specific to the type of tool. For example, the
\code{code_interpreter} tool requires a list of file IDs, while the
\code{file_search} tool requires a list of vector store IDs. See
\url{https://platform.openai.com/docs/api-reference/assistants/createAssistant}
for details.}

\item{metadata}{List. Set of 16 key-value pairs that can be attached to an
assistant. This can be useful for storing additional information about the
assistant in a structured format. Keys can be a maximum of 64 characters
long and values can be a maximum of 512 characters long.}

\item{temperature}{Number or NULL. Optional. Defaults to 1. What sampling
temperature to use, between 0 and 2. Higher values like 0.8 will make the
output more random, while lower values like 0.2 will make it more focused
and deterministic.}

\item{top_p}{Number or NULL. Optional. Defaults to 1. An alternative to
sampling with temperature, called nucleus sampling, where the model
considers the results of the tokens with top_p probability mass. So 0.1
means only the tokens comprising the top 10\% probability mass are
considered. OpenAI generally recommends altering this or temperature but
not both.}

\item{response_format}{A character "auto" or a list. Optional Specifies the
format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and
all GPT-3.5 Turbo models since gpt-3.5-turbo-1106. Setting to a list that
corresponds to the JSON \verb{\{ "type": "json_schema", "json_schema": \{...\} \}}
enables Structured Outputs which ensures the model will match your supplied
JSON schema. Learn more in the \href{https://platform.openai.com/docs/guides/structured-outputs}{Structured Outputs} guide.
Setting to \code{{ "type": "json_object" }} enables JSON mode, which ensures the
message the model generates is valid JSON. Important: when using JSON mode,
you must also instruct the model to produce JSON yourself via a system or
user message. Without this, the model may generate an unending stream of
whitespace until the generation reaches the token limit, resulting in a
long-running and seemingly "stuck" request. Also note that the message
content may be partially cut off if finish_reason="length", which indicates
the generation exceeded max_tokens or the conversation exceeded the max
context length.}

\item{limit}{Integer. Maximum number of results to return (default: 20).}

\item{order}{Character. Sort order (\code{asc} or \code{desc}) based on creation
timestamp.}

\item{after}{Character. Cursor for pagination to fetch results after this ID.}

\item{before}{Character. Cursor for pagination to fetch results before this
ID.}

\item{assistant_id}{Character. ID of the assistant.}
}
\value{
For \code{openai_create_assistant}, \code{openai_get_assistant}, or
\code{openai_update_assistant}, a list containing the following elements:
\itemize{
\item \code{id}: string. The identifier, which can be referenced in API endpoints.
\item \code{object}: string. The object type, which is always "assistant".
\item \code{created_at}: integer. The Unix timestamp (in seconds) for when the assistant was created.
\item \code{name}: string or \code{NULL}. The name of the assistant. The maximum length is 256 characters.
\item \code{description}: string or \code{NULL}. The description of the assistant. The maximum length is 512 characters.
\item \code{model}: string. ID of the model to use. Use the \code{\link[=list_models]{list_models()}} to see all available models or refer to the \href{https://platform.openai.com/docs/models}{Model Overview} for descriptions.
\item \code{instructions}: string or \code{NULL}. The system instructions that the assistant uses. The maximum length is 256,000 characters.
\item \code{tools}: array. A list of tools enabled on the assistant. Maximum of 128 tools per assistant. Tools can be of types \code{"code_interpreter"}, \code{"file_search"}, or \code{"function"}.
\item \code{tool_resources}: object or \code{NULL}. A set of resources used by the assistant's tools. The resources are specific to the type of tool. For example, the \code{"code_interpreter"} tool requires a list of file IDs, while the \code{"file_search"} tool requires a list of vector store IDs.
\item \code{metadata}: map. A set of up to 16 key-value pairs that can be attached to the object. Useful for storing additional information in a structured format. Keys can be a maximum of 64 characters long, and values can be a maximum of 512 characters long.
\item \code{temperature}: number or \code{NULL}. Sampling temperature to use, between 0 and 2. Defaults to 0.2. Higher values like 0.8 make output more random, while lower values like 0.2 make it more focused and deterministic.
\item \code{top_p}: number or \code{NULL}. An alternative to sampling with temperature, called nucleus sampling. \code{top_p} specifies the cumulative probability mass of the tokens to consider. For example, \code{top_p = 0.1} considers only the tokens comprising the top 10\% probability mass. Altering this or \code{temperature}, but not both, is recommended.
\item \code{response_format}: \code{"auto"} or object. Specifies the format the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since \code{"gpt-3.5-turbo-1106"}. Supported formats:
\itemize{
\item \code{type: "json_schema"}: Ensures the model matches a supplied JSON schema. Learn more in the \href{https://platform.openai.com/docs/guides/structured-outputs}{Structured Outputs guide}.
\item \code{type: "json_object"}: Ensures the message the model generates is valid JSON.
}
}

For \code{openai_list_assistants}, a list of assistant objects.

For \code{openai_delete_assistant}, a list with the deletion status.
}
\description{
These functions interact at a low level with the \href{https://platform.openai.com/docs/api-reference/assistants}{OpenAI Assistants API}. Check the
official documentation for details.
}
\examples{
\dontrun{
openai_create_assistant(
  name = "Math Tutor",
  instructions = paste("You are a personal math tutor.",
                       "When asked a question, write and ",
                       "run Python code to answer the question."),
  model = "gpt-4o",
  tools = list(type = "code_interpreter")
  )
}
}
\seealso{
Other openai: 
\code{\link{openai_batch_job}()},
\code{\link{openai_cancel_batch}()},
\code{\link{openai_check_batch_status}()},
\code{\link{openai_create_message}()},
\code{\link{openai_create_run}()},
\code{\link{openai_create_thread}()},
\code{\link{openai_create_vector_store}()},
\code{\link{openai_create_vector_store_file}()},
\code{\link{openai_create_vector_store_file_batch}()},
\code{\link{openai_download_batch_results}()},
\code{\link{openai_list_batches}()},
\code{\link{openai_list_run_steps}()},
\code{\link{openai_poll_and_download}()},
\code{\link{openai_single_request}()},
\code{\link{openai_submit_tool_outputs}()},
\code{\link{openai_upload_file}()}

Other assistants: 
\code{\link{openai_list_run_steps}()},
\code{\link{openai_submit_tool_outputs}()}
}
\concept{assistants}
\concept{openai}
